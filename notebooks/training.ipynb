{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\majd2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\majd2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "BASE_PATH = \"D:\\\\University\\\\7 Fall 2023\\\\CMSC516\\\\Project 1\\\\Datasets\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(BASE_PATH + \"preprocessed_dataset.csv\", encoding='utf_8')\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for tweet in dataset['tweet']:\n",
    "    max_len = max(len(tweet), max_len)\n",
    "print(max_len)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', force_download=True)\n",
    "labels_dict = {'negative':0, 'positive':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels_dict[label] for label in df['label']]\n",
    "        self.texts  = [tokenizer(text, padding='max_length', max_length = 250, \n",
    "                      truncation=True, return_tensors=\"pt\") for text in df['tweet']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bfc27490fa1961d11913dd213748aabeee9b5ee1ac81d5737fca599705f453b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
